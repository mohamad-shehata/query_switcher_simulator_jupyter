{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:08:42.686266Z",
     "start_time": "2025-02-28T14:06:48.565338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "daily_aggregated_data = None\n",
    "daily_aggregated_partial_agg_data = None\n",
    "daily_total_hits = None\n",
    "query_country_date = None\n",
    "real_avg_gmv = None\n",
    "daily_engine_data = None\n",
    "\n",
    "daily_aggregated_raw_data = pd.read_csv(\"../data/daily_aggregated_data.csv\")\n",
    "daily_aggregated_data = (\n",
    "    daily_aggregated_raw_data\n",
    "    .groupby([\"query\", \"country\", \"search_engine\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"avg_gmv\", \"std_gmv\", \"min_cap\", \"max_cap\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")\n",
    "\n",
    "daily_aggregated_data_partial_agg_raw_data = pd.read_csv(\"../data/daily_aggregated_data_partial_agg.csv\")\n",
    "daily_aggregated_partial_agg_data = (\n",
    "    daily_aggregated_data_partial_agg_raw_data\n",
    "    .groupby([\"query\", \"country\", \"search_engine\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"avg_gmv\", \"std_gmv\", \"min_cap\", \"max_cap\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")\n",
    "daily_total_hits_raw_data = pd.read_csv(\"../data/daily_hits.csv\")\n",
    "daily_total_hits = (\n",
    "    daily_total_hits_raw_data\n",
    "    .groupby([\"query\", \"country\", \"date\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"total_day_hits\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")\n",
    "\n",
    "query_country_date_raw_data = pd.read_csv(\"../data/query_country_date.csv\")\n",
    "query_country_date = (\n",
    "    query_country_date_raw_data\n",
    "    .groupby([\"query\", \"country\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"min_date\", \"max_date\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")\n",
    "\n",
    "real_avg_gmv_raw_data = pd.read_csv(\"../data/real_avg_gmv.csv\")\n",
    "real_avg_gmv = (\n",
    "    real_avg_gmv_raw_data\n",
    "    .groupby([\"query\", \"country\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"total_real_avg_gmv\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")\n",
    "\n",
    "daily_engine_data_raw_data = pd.read_csv(\"../data/daily_engine_data.csv\")\n",
    "daily_engine_data = (\n",
    "    daily_engine_data_raw_data\n",
    "    .groupby([\"query\", \"country\", \"search_engine\", \"date\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"total_daily_hits\", \"total_daily_gmv\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:08:48.178236Z",
     "start_time": "2025-02-28T14:08:48.168914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Lodaer Reader\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def get_gmv_data(query: str, country: str, engine: str) -> Tuple[float, float, float, float]:\n",
    "    if daily_aggregated_data is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country, engine) not in daily_aggregated_data:\n",
    "        return NOT_VALID_DATA, NOT_VALID_DATA, NOT_VALID_DATA, NOT_VALID_DATA\n",
    "\n",
    "    avg_gmv = daily_aggregated_data[query, country, engine][\"avg_gmv\"]\n",
    "    std_gmv = daily_aggregated_data[query, country, engine][\"std_gmv\"]\n",
    "    min_cap = daily_aggregated_data[query, country, engine][\"min_cap\"]\n",
    "    max_cap = daily_aggregated_data[query, country, engine][\"max_cap\"]\n",
    "\n",
    "    return avg_gmv, std_gmv, min_cap, max_cap\n",
    "\n",
    "\n",
    "def get_gmv_data_partial_agg(query: str, country: str, engine: str) -> Tuple[float, float, float, float]:\n",
    "    if daily_aggregated_partial_agg_data is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country, engine) not in daily_aggregated_partial_agg_data:\n",
    "        return NOT_VALID_DATA, NOT_VALID_DATA, NOT_VALID_DATA, NOT_VALID_DATA\n",
    "\n",
    "    avg_gmv = daily_aggregated_partial_agg_data[query, country, engine][\"avg_gmv\"]\n",
    "    std_gmv = daily_aggregated_partial_agg_data[query, country, engine][\"std_gmv\"]\n",
    "    min_cap = daily_aggregated_partial_agg_data[query, country, engine][\"min_cap\"]\n",
    "    max_cap = daily_aggregated_partial_agg_data[query, country, engine][\"max_cap\"]\n",
    "\n",
    "    return avg_gmv, std_gmv, min_cap, max_cap\n",
    "\n",
    "\n",
    "def get_daily_total_hits(query: str, country: str, date: str) -> int:\n",
    "    if daily_total_hits is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country, date) not in daily_total_hits:\n",
    "        return NOT_VALID_DATA\n",
    "\n",
    "    if daily_total_hits[query, country, date][\"total_day_hits\"] is not None:\n",
    "        return daily_total_hits[query, country, date][\"total_day_hits\"]\n",
    "\n",
    "    return NOT_VALID_DATA\n",
    "\n",
    "\n",
    "def get_all_query_time_range(query: str, country: str) -> Tuple[str, str]:\n",
    "    if query_country_date is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country) not in query_country_date:\n",
    "        return NOT_VALID_DATA, NOT_VALID_DATA\n",
    "\n",
    "    return (query_country_date[query, country][\"min_date\"],\n",
    "            query_country_date[query, country][\"max_date\"])\n",
    "\n",
    "\n",
    "def get_real_avg_gmv(query: str, country: str) -> float:\n",
    "    if real_avg_gmv is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country) not in real_avg_gmv:\n",
    "        return NOT_VALID_DATA\n",
    "\n",
    "    return real_avg_gmv[query, country][\"total_real_avg_gmv\"]\n",
    "\n",
    "\n",
    "def get_daily_engine_data(query: str, country: str, engine: str, date: str) -> Tuple[float, int]:\n",
    "    if daily_engine_data is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country, engine, date) not in daily_engine_data:\n",
    "        return NOT_VALID_DATA, NOT_VALID_DATA\n",
    "\n",
    "    total_daily_gmv = daily_engine_data[query, country, engine, date][\"total_daily_gmv\"]\n",
    "    total_daily_hits = daily_engine_data[query, country, engine, date][\"total_daily_hits\"]\n",
    "    return total_daily_gmv, total_daily_hits"
   ],
   "id": "777cd7248316d923",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:46:14.757074Z",
     "start_time": "2025-02-28T14:46:14.754966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "\n",
    "NOT_VALID_DATA = -1.0\n",
    "Z_SCORE = 1.96\n",
    "DEFAULT_ENGINES_SPLIT = {\n",
    "    'elastic': 0.2,\n",
    "    'google': 0.8\n",
    "}"
   ],
   "id": "3d5bd903ec3254e7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:46:23.135052Z",
     "start_time": "2025-02-28T14:46:22.939922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Utils\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "def generate_gmv_sample(avg: float, std: float, min_cap: float, max_cap: float) -> float:\n",
    "    selected_gmv = np.random.normal(avg, std)\n",
    "    return min(max_cap, max(selected_gmv, min_cap))  # capping"
   ],
   "id": "f69a076250e60b25",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:46:27.614640Z",
     "start_time": "2025-02-28T14:46:27.607035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Algorithms\n",
    "\n",
    "from typing import List\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class ScoringAlgorithm(ABC):\n",
    "    @abstractmethod\n",
    "    def get_score(self, engines_gmvs: List[float]) -> List[float]:\n",
    "        pass\n",
    "\n",
    "\n",
    "class UCBScoringAlgorithm(ScoringAlgorithm):\n",
    "\n",
    "    def __init__(self, S: float, C: float):\n",
    "        self.S = S\n",
    "        self.C = C\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"UCB: S:{self.S}, C:{self.C}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"UCB: S:{self.S}, C:{self.C}\"\n",
    "\n",
    "    def get_score(self, engines_gmvs: List[float]) -> List[float]:\n",
    "        total_engine_hits = sum(len(engine_gmv) for engine_gmv in engines_gmvs)\n",
    "        agg_hits = [len(engine_gmv) for engine_gmv in engines_gmvs]\n",
    "        agg_gmvs = [sum(engine_gmv) for engine_gmv in engines_gmvs]\n",
    "\n",
    "        agg_gmvs = np.array(agg_gmvs)\n",
    "        agg_hits = np.array(agg_hits)\n",
    "        agg_hits = np.maximum(agg_hits, 1)\n",
    "        ucb_res = softmax((agg_gmvs + self.C * np.sqrt(np.log(total_engine_hits) / agg_hits)) * self.S)\n",
    "\n",
    "        return ucb_res.tolist()\n",
    "\n",
    "\n",
    "THOMPSON_ITERATIONS = 10000\n",
    "\n",
    "\n",
    "class ThompsonScoringAlgorithm(ScoringAlgorithm):\n",
    "\n",
    "    def __init__(self, S: float, n_iterations=THOMPSON_ITERATIONS):\n",
    "        self.S = S\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"TS: S:{self.S}, N:{self.n_iterations}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TS: S:{self.S}, N:{self.n_iterations}\"\n",
    "\n",
    "    def get_score(self, engines_gmvs: List[float]) -> List[float]:\n",
    "        avg_gmvs = [np.mean(engine_gmvs) for engine_gmvs in engines_gmvs]\n",
    "        std_gmvs = [np.std(engine_gmvs) for engine_gmvs in engines_gmvs]\n",
    "        min_caps = [max(0, avg - std * Z_SCORE) for avg, std in zip(avg_gmvs, std_gmvs)]\n",
    "        max_caps = [avg + std * Z_SCORE for avg, std in zip(avg_gmvs, std_gmvs)]\n",
    "\n",
    "        num_elements = len(engines_gmvs)\n",
    "        scores = [0] * num_elements\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            sampled_gmvs = [generate_gmv_sample(avg, std, min_cap, max_cap) for avg, std, min_cap, max_cap in\n",
    "                            zip(avg_gmvs, std_gmvs, min_caps, max_caps)]\n",
    "            max_sampled_gmv = max(sampled_gmvs)\n",
    "            scores = [score + 1 if sampled_gmv == max_sampled_gmv else score for score, sampled_gmv in\n",
    "                      zip(scores, sampled_gmvs)]\n",
    "\n",
    "        scores = np.array(scores)\n",
    "        thompson_res = softmax((scores / self.n_iterations) * self.S)\n",
    "\n",
    "        return thompson_res.tolist()\n",
    "\n"
   ],
   "id": "f7a82d8e394922ce",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:46:31.895113Z",
     "start_time": "2025-02-28T14:46:31.884519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# processing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class SimulationResult:\n",
    "    def __init__(self):\n",
    "        self.total_avg_regrets: List[float] = []\n",
    "        self.total_avg_real_regrets: List[float] = []\n",
    "        self.avg_gmvs: List[float] = []\n",
    "        self.total_avg_real_gmvs: List[float] = []\n",
    "        self.engines_ranges: List[dict[str, float]] = []\n",
    "        self.days: List[str] = []\n",
    "\n",
    "\n",
    "class EngineAggData:\n",
    "    def __init__(self, avg_gmv: float, std_gmv: float, min_cap: float, max_cap: float):\n",
    "        self.avg_gmv = avg_gmv\n",
    "        self.std_gmv = std_gmv\n",
    "        self.min_cap = min_cap\n",
    "        self.max_cap = max_cap\n",
    "\n",
    "\n",
    "class EngineDailyData:\n",
    "    def __init__(self, daily_gmv: float, daily_hits: int):\n",
    "        self.daily_gmv = daily_gmv\n",
    "        self.daily_hits = daily_hits\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, total_gmv: float, total_regret: float, total_hits: int):\n",
    "        self.total_gmv = total_gmv\n",
    "        self.total_regret = total_regret\n",
    "        self.total_hits = total_hits\n",
    "\n",
    "\n",
    "def run_algorithm(query: str, country: str, start_date: str, end_date: str,\n",
    "                  scoring_algorithm: ScoringAlgorithm, engines: List[str] = None,\n",
    "                  default_ranges=dict[str, float]) -> SimulationResult:\n",
    "    if engines is None:\n",
    "        engines = ['elastic', 'google']\n",
    "\n",
    "    algo_data = Data(0, 0, 0)\n",
    "    real_data = Data(0, 0, 0)\n",
    "    engines_sofar_gmv = {engine: [] for engine in engines}\n",
    "    engines_range = {engine: 1 / len(engines) for engine in engines}\n",
    "    if default_ranges is not None:\n",
    "        engines_range = default_ranges\n",
    "    simulationResult = SimulationResult()\n",
    "\n",
    "    # Get the real aggregated gmv data for each engine\n",
    "    engines_agg_data = {}\n",
    "    for engine in engines:\n",
    "        avg_gmv, std_gmv, min_cap, max_cap = get_gmv_data(query, country, engine)\n",
    "        if avg_gmv == NOT_VALID_DATA:\n",
    "            return simulationResult\n",
    "        engines_agg_data[engine] = EngineAggData(avg_gmv, std_gmv, min_cap, max_cap)\n",
    "\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "    for current_date in date_range:\n",
    "        current_date_str = current_date.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Get the real daily gmv data for each engine\n",
    "        engines_daily_data = {}\n",
    "        for engine in engines:\n",
    "            daily_gmv, daily_hits = get_daily_engine_data(query, country, engine, current_date_str)\n",
    "            if daily_hits == NOT_VALID_DATA:\n",
    "                daily_hits, daily_gmv = 0, 0\n",
    "            engines_daily_data[engine] = EngineDailyData(daily_gmv, daily_hits)\n",
    "\n",
    "        total_daily_hits = get_daily_total_hits(query, country, current_date_str)\n",
    "        # If data is not available for the current date, skip the current iteration\n",
    "        if total_daily_hits == NOT_VALID_DATA:\n",
    "            continue\n",
    "\n",
    "        # Get the daily algo hits for each engine\n",
    "        engines_daily_algo_hits = {}\n",
    "        for engine in engines:\n",
    "            engines_daily_algo_hits[engine] = round(total_daily_hits * engines_range[engine])\n",
    "            algo_data.total_hits += engines_daily_algo_hits[engine]\n",
    "\n",
    "        # Make sure that total_daily_hits has the same value as the sum of the hits of the all engines\n",
    "        total_daily_hits = sum(engines_daily_algo_hits.values())\n",
    "        algo_data.total_gmv += total_daily_hits\n",
    "\n",
    "        # Aggregate the total real hits for all engines\n",
    "        for engine in engines:\n",
    "            real_data.total_hits += engines_daily_data[engine].daily_hits\n",
    "\n",
    "        total_algo_daily_selected_gmv = 0\n",
    "\n",
    "        # Simulate engines gmvs\n",
    "        for engine in engines:\n",
    "            for _ in range(engines_daily_algo_hits[engine]):\n",
    "                gmv_sample = generate_gmv_sample(engines_agg_data[engine].avg_gmv, engines_agg_data[engine].std_gmv,\n",
    "                                                 engines_agg_data[engine].min_cap, engines_agg_data[engine].max_cap)\n",
    "                total_algo_daily_selected_gmv += gmv_sample\n",
    "                engines_sofar_gmv[engine].append(gmv_sample)\n",
    "\n",
    "        algo_data.total_gmv += total_algo_daily_selected_gmv\n",
    "        simulationResult.avg_gmvs.append(algo_data.total_gmv / algo_data.total_hits)\n",
    "\n",
    "        # Best daily gmv is the max avg gmv of all engines multiplied by the total daily hits\n",
    "        best_gmv = max([engines_agg_data[engine].avg_gmv for engine in engines]) * total_daily_hits\n",
    "        # Best real gmv is the max avg gmv of all engines multiplied by the total real hits\n",
    "        best_real_gmv = max([engines_agg_data[engine].avg_gmv for engine in engines]) * sum(\n",
    "            [engines_daily_data[engine].daily_hits for engine in engines])\n",
    "\n",
    "        # Calc algo regret\n",
    "        algo_data.total_regret += max(0, best_gmv - total_algo_daily_selected_gmv)\n",
    "        simulationResult.total_avg_regrets.append(algo_data.total_regret / algo_data.total_hits)\n",
    "\n",
    "        # Calc real regret\n",
    "        real_data.total_regret += max(0,\n",
    "                                      best_real_gmv - sum([engines_daily_data[engine].daily_gmv for engine in engines]))\n",
    "        simulationResult.total_avg_real_regrets.append(real_data.total_regret / real_data.total_hits)\n",
    "\n",
    "        # Calc real gmv\n",
    "        real_data.total_gmv += (sum([engines_daily_data[engine].daily_gmv for engine in engines]))\n",
    "        simulationResult.total_avg_real_gmvs.append(real_data.total_gmv / real_data.total_hits)\n",
    "\n",
    "        # Calc ranges\n",
    "        #engines_range = {engine: 1 / len(engines) for engine in engines}\n",
    "        algo_scores = scoring_algorithm.get_score([engines_sofar_gmv[engine] for engine in engines])\n",
    "        engines_range = {engine: rng for engine, rng in zip(engines, algo_scores)}\n",
    "        simulationResult.engines_ranges.append(engines_range)\n",
    "\n",
    "        # Log days\n",
    "        simulationResult.days.append(current_date_str)\n",
    "\n",
    "    return simulationResult"
   ],
   "id": "59686ccf9892cd86",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:39:18.161944Z",
     "start_time": "2025-02-27T18:39:18.150177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#     total_avg_gmv_res += algorithm_avg_gmv_res\n",
    "#     total_regret_res += algorithm_avg_regret_res\n",
    "#     total_real_avg_gmv_res += curr_real_avg_gmv_res\n",
    "#     total_real_regret_res += real_avg_regret_res\n",
    "#\n",
    "# total_avg_gmv_res /= N\n",
    "# total_regret_res /= N\n",
    "# total_real_avg_gmv_res /= N\n",
    "# total_real_regret_res /= N\n",
    "\n",
    "# print(total_avg_gmv_res, total_regret_res, total_real_avg_gmv_res, total_real_regret_res, curr_range_res)\n",
    "#  -----------------------------------------------------------\n",
    "# | ThompsonScoringAlgorithm                                  |\n",
    "# | SOFTMAX_SENSITIVITY min = 0.128 max = 65.536              |\n",
    "# |                                                           |\n",
    "# | UCBScoringAlgorithm                                       |\n",
    "# | UCB_CONFIDENCE = 10000                                    |\n",
    "# | SOFTMAX_SENSITIVITY min = 2.62144e-06 max = 0.00067108864 |\n",
    "#  -----------------------------------------------------------\n"
   ],
   "id": "6f717b674ba56e26",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T14:35:53.466863Z",
     "start_time": "2025-02-22T14:35:53.092453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drow\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def show_graph(values_to_draw: List[float], days: List[str], graph_title: str, graph_label: str,\n",
    "               graph_color: str = 'b'):\n",
    "    graph_days = pd.to_datetime(days)\n",
    "    plt.plot(graph_days, values_to_draw, color=graph_color, label=graph_label)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel(graph_label)\n",
    "    plt.title(graph_title)\n",
    "    plt.gca().xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_graph_multiple(values_to_draw: List[List[float]], days: List[str], ylabel: str, graph_title: str,\n",
    "                        graph_labels: List[str]):\n",
    "    graph_days = pd.to_datetime(days)\n",
    "    for i in range(len(values_to_draw)):\n",
    "        plt.plot(graph_days, values_to_draw[i], label=graph_labels[i])\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(graph_title)\n",
    "    plt.gca().xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    plt.legend(fontsize=8, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.style.use('dark_background')\n",
    "    plt.figure(figsize=(16, 10))\n",
    "\n",
    "    plt.show()"
   ],
   "id": "f669aba0f3d8ca4b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T18:30:31.287107Z",
     "start_time": "2025-02-28T14:46:41.414347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "# Start Experiment Thompson\n",
    "\n",
    "# Custom queries to train with\n",
    "queries_train = [\n",
    "    ('ملصقات', 'sa', '2025-01-02', '2025-02-01')\n",
    "    , ('مزيل عرق', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('adidas shoes', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('جزمة رجالي', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('puma shoes for men', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('boots', 'eg', '2025-01-02', '2025-02-01'),\n",
    "    ('samsung', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('شنط جس', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('boots for ladies', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('abaya', 'ae', '2025-01-02', '2025-02-01'),\n",
    "    ('iphone 11', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('ماكينة حلاقة', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('airpods', 'ae', '2025-01-02', '2025-02-01'),\n",
    "    ('استشوار شعر', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('سماعه بلوتوث', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('ابجوره طويله', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('لوحه جداريه', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('نيو بالانس احذية نسائية', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('new balance shoes for men', 'ae', '2025-01-02', '2025-02-01'),\n",
    "    ('العاب', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('iphone 13 pro max', 'sa', '2025-01-02', '2025-02-01')\n",
    "]\n",
    "\n",
    "column_order = ['query', 'country', 'min_date', 'max_date']\n",
    "query_country_date_raw_data = query_country_date_raw_data[column_order]\n",
    "start = 0.128\n",
    "end = 65.536\n",
    "num_of_steps = 5\n",
    "sensitivities = np.logspace(np.log10(start), np.log10(end), num=num_of_steps)\n",
    "ALGO_N_ITERATIONS = 10\n",
    "\n",
    "experiment_results = pd.DataFrame(\n",
    "    columns=['query', 'country', 'date', 'engines_range', 'config', 'algo_regret', 'real_regret', 'algo_gmv',\n",
    "             'real_gmv'])\n",
    "total_queries = len(queries_train)  #len(query_country_date_raw_data)\n",
    "\n",
    "for query_it, country_it, start_date_it, end_date_it in queries_train:  #query_country_date_raw_data.itertuples(index=False, name=None):\n",
    "    elastic_avg_gmv, elastic_std_gmv, elastic_min_cap, elastic_max_cap = get_gmv_data_partial_agg('كنب', 'sa',\n",
    "                                                                                                  'elastic')\n",
    "    google_avg_gmv, google_std_gmv, google_min_cap, google_max_cap = get_gmv_data_partial_agg('كنب', 'sa', 'google')\n",
    "    if elastic_avg_gmv == NOT_VALID_DATA or google_avg_gmv == NOT_VALID_DATA:\n",
    "        continue\n",
    "\n",
    "    tot_avg = elastic_avg_gmv + google_avg_gmv\n",
    "    if (elastic_avg_gmv / tot_avg) - (google_avg_gmv / tot_avg) > 0.1:\n",
    "        DEFAULT_ENGINES_SPLIT = {\n",
    "            'elastic': 0.8,\n",
    "            'google': 0.2\n",
    "        }\n",
    "    elif (google_avg_gmv / tot_avg) - (elastic_avg_gmv / tot_avg) > 0.1:\n",
    "        DEFAULT_ENGINES_SPLIT = {\n",
    "            'elastic': 0.2,\n",
    "            'google': 0.8\n",
    "        }\n",
    "    else:\n",
    "        DEFAULT_ENGINES_SPLIT = {\n",
    "            'elastic': 0.5,\n",
    "            'google': 0.5\n",
    "        }\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    for sensitivity in sensitivities:\n",
    "        res = run_algorithm(\n",
    "            query_it, country_it, start_date_it, end_date_it, ThompsonScoringAlgorithm(sensitivity, 10000),\n",
    "            ['elastic', 'google'], DEFAULT_ENGINES_SPLIT)\n",
    "\n",
    "        if len(res.days) == 0:\n",
    "            break\n",
    "\n",
    "        for _ in range(ALGO_N_ITERATIONS - 1):\n",
    "            temp = run_algorithm(\n",
    "                query_it, country_it, start_date_it, end_date_it, ThompsonScoringAlgorithm(sensitivity, 10000),\n",
    "                ['elastic', 'google'], DEFAULT_ENGINES_SPLIT)\n",
    "            res.total_avg_regrets = [x + y for x, y in zip(res.total_avg_regrets, temp.total_avg_regrets)]\n",
    "            res.total_avg_real_regrets = [x + y for x, y in\n",
    "                                          zip(res.total_avg_real_regrets, temp.total_avg_real_regrets)]\n",
    "            res.avg_gmvs = [x + y for x, y in zip(res.avg_gmvs, temp.avg_gmvs)]\n",
    "            res.total_avg_real_gmvs = [x + y for x, y in zip(res.total_avg_real_gmvs, temp.total_avg_real_gmvs)]\n",
    "            for i in range(len(res.engines_ranges)):\n",
    "                for k in res.engines_ranges[i].keys():\n",
    "                    res.engines_ranges[i][k] += temp.engines_ranges[i][k]\n",
    "\n",
    "        res.total_avg_regrets = [x / ALGO_N_ITERATIONS for x in res.total_avg_regrets]\n",
    "        res.total_avg_real_regrets = [x / ALGO_N_ITERATIONS for x in res.total_avg_real_regrets]\n",
    "        res.avg_gmvs = [x / ALGO_N_ITERATIONS for x in res.avg_gmvs]\n",
    "        res.total_avg_real_gmvs = [x / ALGO_N_ITERATIONS for x in res.total_avg_real_gmvs]\n",
    "        for i in range(len(res.engines_ranges)):\n",
    "            for k in res.engines_ranges[i].keys():\n",
    "                res.engines_ranges[i][k] /= ALGO_N_ITERATIONS\n",
    "\n",
    "        result_data = {}\n",
    "\n",
    "        result_data['query'] = [query_it] * len(res.days)\n",
    "        result_data['country'] = [country_it] * len(res.days)\n",
    "        result_data['date'] = res.days\n",
    "        result_data['engines_range'] = res.engines_ranges\n",
    "        result_data['config'] = [ThompsonScoringAlgorithm(sensitivity)] * len(res.days)\n",
    "        result_data['algo_regret'] = res.total_avg_regrets\n",
    "        result_data['real_regret'] = res.total_avg_real_regrets\n",
    "        result_data['algo_gmv'] = res.avg_gmvs\n",
    "        result_data['real_gmv'] = res.total_avg_real_gmvs\n",
    "\n",
    "        experiment_results = pd.concat([experiment_results, pd.DataFrame(result_data)])\n",
    "        # show_graph_multiple([[x.left for x in res.engines_ranges], [x.right for x in res.engines_ranges]], res.days, f'engines_ranges over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', ['elastic', 'google'], ['b', 'r'])\n",
    "        # show_graph(res.total_avg_regrets, res.days, f'avg_regret over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_regret', 'r')\n",
    "        # show_graph(res.total_avg_real_regrets, res.days, f'avg_real_regret over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_real_regret', 'g')\n",
    "        # show_graph(res.avg_gmvs, res.days, f'avg_gmv over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_gmv', 'b')\n",
    "    end_time = time.perf_counter()\n",
    "    process_time = (end_time - start_time) / 60\n",
    "    total_queries -= 1\n",
    "    print(\"processing done for query: \", query_it, \"country: \", country_it, 'in ', process_time, 'minutes',\n",
    "          \"remaining queries: \", total_queries)\n",
    "print(experiment_results)"
   ],
   "id": "b011f0a378c8dfc5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/jmjmqm7n6b1415qd1jn3wqj54k6k6k/T/ipykernel_52157/3943566748.py:109: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  experiment_results = pd.concat([experiment_results, pd.DataFrame(result_data)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing done for query:  ملصقات country:  sa in  0.5926620666665258 minutes remaining queries:  20\n",
      "processing done for query:  مزيل عرق country:  sa in  0.5914564236169099 minutes remaining queries:  19\n",
      "processing done for query:  adidas shoes country:  sa in  0.58840899651647 minutes remaining queries:  18\n",
      "processing done for query:  جزمة رجالي country:  sa in  0.58145470485033 minutes remaining queries:  17\n",
      "processing done for query:  puma shoes for men country:  sa in  0.6141202194330011 minutes remaining queries:  16\n",
      "processing done for query:  boots country:  eg in  0.5808133687499019 minutes remaining queries:  15\n",
      "processing done for query:  samsung country:  sa in  0.6415172236166351 minutes remaining queries:  14\n",
      "processing done for query:  شنط جس country:  sa in  0.587206656250055 minutes remaining queries:  13\n",
      "processing done for query:  boots for ladies country:  sa in  0.5832644902669321 minutes remaining queries:  12\n",
      "processing done for query:  abaya country:  ae in  0.5883712264000981 minutes remaining queries:  11\n",
      "processing done for query:  iphone 11 country:  sa in  0.6038641875003425 minutes remaining queries:  10\n",
      "processing done for query:  ماكينة حلاقة country:  sa in  0.5897775333331083 minutes remaining queries:  9\n",
      "processing done for query:  airpods country:  ae in  0.6459153944500334 minutes remaining queries:  8\n",
      "processing done for query:  استشوار شعر country:  sa in  0.6152742854169143 minutes remaining queries:  7\n",
      "processing done for query:  سماعه بلوتوث country:  sa in  0.6304616319500685 minutes remaining queries:  6\n",
      "processing done for query:  ابجوره طويله country:  sa in  0.5925235979166852 minutes remaining queries:  5\n",
      "processing done for query:  لوحه جداريه country:  sa in  0.591546605550199 minutes remaining queries:  4\n",
      "processing done for query:  نيو بالانس احذية نسائية country:  sa in  0.5776929472170499 minutes remaining queries:  3\n",
      "processing done for query:  new balance shoes for men country:  ae in  0.5872473250002561 minutes remaining queries:  2\n",
      "processing done for query:  العاب country:  sa in  0.6732180805503352 minutes remaining queries:  1\n",
      "processing done for query:  iphone 13 pro max country:  sa in  0.6690895708331178 minutes remaining queries:  0\n",
      "                query country        date  \\\n",
      "0              ملصقات      sa  2025-01-02   \n",
      "1              ملصقات      sa  2025-01-03   \n",
      "2              ملصقات      sa  2025-01-04   \n",
      "3              ملصقات      sa  2025-01-05   \n",
      "4              ملصقات      sa  2025-01-06   \n",
      "..                ...     ...         ...   \n",
      "26  iphone 13 pro max      sa  2025-01-28   \n",
      "27  iphone 13 pro max      sa  2025-01-29   \n",
      "28  iphone 13 pro max      sa  2025-01-30   \n",
      "29  iphone 13 pro max      sa  2025-01-31   \n",
      "30  iphone 13 pro max      sa  2025-02-01   \n",
      "\n",
      "                                        engines_range                 config  \\\n",
      "0   {'elastic': 0.4862422376043747, 'google': 0.51...   TS: S:0.128, N:10000   \n",
      "1   {'elastic': 0.4863957150470042, 'google': 0.51...   TS: S:0.128, N:10000   \n",
      "2   {'elastic': 0.4863790896162702, 'google': 0.51...   TS: S:0.128, N:10000   \n",
      "3   {'elastic': 0.48669247950243155, 'google': 0.5...   TS: S:0.128, N:10000   \n",
      "4   {'elastic': 0.48648142587348964, 'google': 0.5...   TS: S:0.128, N:10000   \n",
      "..                                                ...                    ...   \n",
      "26  {'elastic': 0.09243789307120814, 'google': 0.9...  TS: S:65.536, N:10000   \n",
      "27  {'elastic': 0.0749444366914517, 'google': 0.92...  TS: S:65.536, N:10000   \n",
      "28  {'elastic': 0.07057322969451832, 'google': 0.9...  TS: S:65.536, N:10000   \n",
      "29  {'elastic': 0.06632751040674498, 'google': 0.9...  TS: S:65.536, N:10000   \n",
      "30  {'elastic': 0.07189250272222741, 'google': 0.9...  TS: S:65.536, N:10000   \n",
      "\n",
      "    algo_regret  real_regret  algo_gmv  real_gmv  \n",
      "0      0.061948     0.105816  1.236644  0.192777  \n",
      "1      0.059104     0.117489  1.239488  0.181104  \n",
      "2      0.058334     0.079361  1.240258  0.280006  \n",
      "3      0.057923     0.058924  1.240669  0.289363  \n",
      "4      0.058413     0.071316  1.240179  0.267203  \n",
      "..          ...          ...       ...       ...  \n",
      "26     0.026636     1.146715  5.174779  3.901729  \n",
      "27     0.026119     1.154275  5.175177  3.860707  \n",
      "28     0.026022     1.110755  5.175035  4.026138  \n",
      "29     0.025638     1.116668  5.175361  3.984007  \n",
      "30     0.025109     1.110105  5.176107  3.959080  \n",
      "\n",
      "[3255 rows x 9 columns]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T18:31:24.818860Z",
     "start_time": "2025-02-28T18:31:24.789670Z"
    }
   },
   "cell_type": "code",
   "source": "experiment_results.to_csv('../experiment_output/thompson_results_fl10q_historical_rng.csv', index=False)",
   "id": "a4a7163cb944d837",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T18:32:29.937011Z",
     "start_time": "2025-02-28T18:32:03.323684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "# Start Experiment UCB\n",
    "\n",
    "queries_train_ucb = [\n",
    "    ('ملصقات', 'sa', '2025-01-02', '2025-02-01')\n",
    "    , ('مزيل عرق', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('adidas shoes', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('جزمة رجالي', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('puma shoes for men', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('boots', 'eg', '2025-01-02', '2025-02-01'),\n",
    "    ('samsung', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('شنط جس', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('boots for ladies', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('abaya', 'ae', '2025-01-02', '2025-02-01'),\n",
    "    ('iphone 11', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('ماكينة حلاقة', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('airpods', 'ae', '2025-01-02', '2025-02-01'),\n",
    "    ('استشوار شعر', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('سماعه بلوتوث', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('ابجوره طويله', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('لوحه جداريه', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('نيو بالانس احذية نسائية', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('new balance shoes for men', 'ae', '2025-01-02', '2025-02-01'),\n",
    "    ('العاب', 'sa', '2025-01-02', '2025-02-01'),\n",
    "    ('iphone 13 pro max', 'sa', '2025-01-02', '2025-02-01')\n",
    "]\n",
    "column_order_ucb = ['query', 'country', 'min_date', 'max_date']\n",
    "query_country_date_raw_data_ucb = query_country_date_raw_data[column_order_ucb]\n",
    "\n",
    "start_sens_ucb = 2.62144e-06\n",
    "end_sens_ucb = 0.00067108864\n",
    "start_conf_ucb = 100000\n",
    "end_conf_ucb = 100000\n",
    "num_of_steps_ucb = 1\n",
    "sensitivities_ucb = np.logspace(np.log10(start_sens_ucb), np.log10(end_sens_ucb), num=num_of_steps_ucb)\n",
    "confidences_ucb = np.logspace(np.log10(start_conf_ucb), np.log10(end_conf_ucb), num=num_of_steps_ucb)\n",
    "ALGO_N_ITERATIONS_UCB = 50\n",
    "\n",
    "experiment_results_ucb = pd.DataFrame(\n",
    "    columns=['query', 'country', 'date', 'engines_range', 'config', 'algo_regret', 'real_regret', 'algo_gmv',\n",
    "             'real_gmv'])\n",
    "total_queries_ucb = len(queries_train_ucb)  #len(query_country_date_raw_data)\n",
    "for query_it_ucb, country_it_ucb, start_date_it_ucb, end_date_it_ucb in queries_train_ucb:  #query_country_date_raw_data.itertuples(index=False, name=None):\n",
    "    elastic_avg_gmv, elastic_std_gmv, elastic_min_cap, elastic_max_cap = get_gmv_data_partial_agg('كنب', 'sa',\n",
    "                                                                                                  'elastic')\n",
    "    google_avg_gmv, google_std_gmv, google_min_cap, google_max_cap = get_gmv_data_partial_agg('كنب', 'sa', 'google')\n",
    "    if elastic_avg_gmv == NOT_VALID_DATA or google_avg_gmv == NOT_VALID_DATA:\n",
    "        continue\n",
    "\n",
    "    tot_avg = elastic_avg_gmv + google_avg_gmv\n",
    "    if (elastic_avg_gmv / tot_avg) - (google_avg_gmv / tot_avg) > 0.1:\n",
    "        DEFAULT_ENGINES_SPLIT = {\n",
    "            'elastic': 0.8,\n",
    "            'google': 0.2\n",
    "        }\n",
    "    elif (google_avg_gmv / tot_avg) - (elastic_avg_gmv / tot_avg) > 0.1:\n",
    "        DEFAULT_ENGINES_SPLIT = {\n",
    "            'elastic': 0.2,\n",
    "            'google': 0.8\n",
    "        }\n",
    "    else:\n",
    "        DEFAULT_ENGINES_SPLIT = {\n",
    "            'elastic': 0.5,\n",
    "            'google': 0.5\n",
    "        }\n",
    "\n",
    "    start_time_ucb = time.perf_counter()\n",
    "    for sensitivity_ucb in sensitivities_ucb:\n",
    "        for confidence_ucb in confidences_ucb:\n",
    "            res_ucb = run_algorithm(\n",
    "                query_it_ucb, country_it_ucb, start_date_it_ucb, end_date_it_ucb,\n",
    "                UCBScoringAlgorithm(sensitivity_ucb, confidence_ucb), ['elastic', 'google'], DEFAULT_ENGINES_SPLIT)\n",
    "\n",
    "            if len(res_ucb.days) == 0:\n",
    "                break\n",
    "\n",
    "            for _ in range(ALGO_N_ITERATIONS_UCB - 1):\n",
    "                temp_ucb = run_algorithm(\n",
    "                    query_it_ucb, country_it_ucb, start_date_it_ucb, end_date_it_ucb,\n",
    "                    UCBScoringAlgorithm(sensitivity_ucb, confidence_ucb), ['elastic', 'google'], DEFAULT_ENGINES_SPLIT)\n",
    "                res_ucb.total_avg_regrets = [x + y for x, y in\n",
    "                                             zip(res_ucb.total_avg_regrets, temp_ucb.total_avg_regrets)]\n",
    "                res_ucb.total_avg_real_regrets = [x + y for x, y in\n",
    "                                                  zip(res_ucb.total_avg_real_regrets, temp_ucb.total_avg_real_regrets)]\n",
    "                res_ucb.avg_gmvs = [x + y for x, y in zip(res_ucb.avg_gmvs, temp_ucb.avg_gmvs)]\n",
    "                res_ucb.total_avg_real_gmvs = [x + y for x, y in\n",
    "                                               zip(res_ucb.total_avg_real_gmvs, temp_ucb.total_avg_real_gmvs)]\n",
    "                for i in range(len(res_ucb.engines_ranges)):\n",
    "                    for k in res_ucb.engines_ranges[i].keys():\n",
    "                        res_ucb.engines_ranges[i][k] += temp_ucb.engines_ranges[i][k]\n",
    "\n",
    "            res_ucb.total_avg_regrets = [x / ALGO_N_ITERATIONS_UCB for x in res_ucb.total_avg_regrets]\n",
    "            res_ucb.total_avg_real_regrets = [x / ALGO_N_ITERATIONS_UCB for x in res_ucb.total_avg_real_regrets]\n",
    "            res_ucb.avg_gmvs = [x / ALGO_N_ITERATIONS_UCB for x in res_ucb.avg_gmvs]\n",
    "            res_ucb.total_avg_real_gmvs = [x / ALGO_N_ITERATIONS_UCB for x in res_ucb.total_avg_real_gmvs]\n",
    "            for i in range(len(res_ucb.engines_ranges)):\n",
    "                for k in res_ucb.engines_ranges[i].keys():\n",
    "                    res_ucb.engines_ranges[i][k] /= ALGO_N_ITERATIONS\n",
    "\n",
    "            result_data_ucb = {}\n",
    "\n",
    "            result_data_ucb['query'] = [query_it_ucb] * len(res_ucb.days)\n",
    "            result_data_ucb['country'] = [country_it_ucb] * len(res_ucb.days)\n",
    "            result_data_ucb['date'] = res_ucb.days\n",
    "            result_data_ucb['engines_range'] = res_ucb.engines_ranges\n",
    "            result_data_ucb['config'] = [UCBScoringAlgorithm(sensitivity_ucb, confidence_ucb)] * len(res_ucb.days)\n",
    "            result_data_ucb['algo_regret'] = res_ucb.total_avg_regrets\n",
    "            result_data_ucb['real_regret'] = res_ucb.total_avg_real_regrets\n",
    "            result_data_ucb['algo_gmv'] = res_ucb.avg_gmvs\n",
    "            result_data_ucb['real_gmv'] = res_ucb.total_avg_real_gmvs\n",
    "\n",
    "            experiment_results_ucb = pd.concat([experiment_results_ucb, pd.DataFrame(result_data_ucb)])\n",
    "            # show_graph_multiple([[x.left for x in res.engines_ranges], [x.right for x in res.engines_ranges]], res.days, f'engines_ranges over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', ['elastic', 'google'], ['b', 'r'])\n",
    "            # show_graph(res.total_avg_regrets, res.days, f'avg_regret over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_regret', 'r')\n",
    "            # show_graph(res.total_avg_real_regrets, res.days, f'avg_real_regret over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_real_regret', 'g')\n",
    "            # show_graph(res.avg_gmvs, res.days, f'avg_gmv over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_gmv', 'b')\n",
    "    end_time_ucb = time.perf_counter()\n",
    "    process_time_ucb = (end_time_ucb - start_time_ucb) / 60\n",
    "    total_queries_ucb -= 1\n",
    "    print(\"processing done for query: \", query_it_ucb, \"country: \", country_it_ucb, 'in ', process_time_ucb, 'minutes',\n",
    "          \"remaining queries: \", total_queries_ucb)\n",
    "print(experiment_results_ucb)"
   ],
   "id": "74a2387fc1e43aa3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/jmjmqm7n6b1415qd1jn3wqj54k6k6k/T/ipykernel_52157/596081670.py:113: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  experiment_results_ucb = pd.concat([experiment_results_ucb, pd.DataFrame(result_data_ucb)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing done for query:  ملصقات country:  sa in  0.01153643263290481 minutes remaining queries:  20\n",
      "processing done for query:  مزيل عرق country:  sa in  0.016358738883476085 minutes remaining queries:  19\n",
      "processing done for query:  adidas shoes country:  sa in  0.0122139298497738 minutes remaining queries:  18\n",
      "processing done for query:  جزمة رجالي country:  sa in  0.009547498617030215 minutes remaining queries:  17\n",
      "processing done for query:  puma shoes for men country:  sa in  0.027377943049941678 minutes remaining queries:  16\n",
      "processing done for query:  boots country:  eg in  0.008943397916542988 minutes remaining queries:  15\n",
      "processing done for query:  samsung country:  sa in  0.04092863124969881 minutes remaining queries:  14\n",
      "processing done for query:  شنط جس country:  sa in  0.00931054098327877 minutes remaining queries:  13\n",
      "processing done for query:  boots for ladies country:  sa in  0.007163708333003645 minutes remaining queries:  12\n",
      "processing done for query:  abaya country:  ae in  0.010410639583036148 minutes remaining queries:  11\n",
      "processing done for query:  iphone 11 country:  sa in  0.019796893050079235 minutes remaining queries:  10\n",
      "processing done for query:  ماكينة حلاقة country:  sa in  0.008969740283403856 minutes remaining queries:  9\n",
      "processing done for query:  airpods country:  ae in  0.032462604166842844 minutes remaining queries:  8\n",
      "processing done for query:  استشوار شعر country:  sa in  0.024713694450232044 minutes remaining queries:  7\n",
      "processing done for query:  سماعه بلوتوث country:  sa in  0.034096527783549394 minutes remaining queries:  6\n",
      "processing done for query:  ابجوره طويله country:  sa in  0.017080025683389975 minutes remaining queries:  5\n",
      "processing done for query:  لوحه جداريه country:  sa in  0.015491875000103997 minutes remaining queries:  4\n",
      "processing done for query:  نيو بالانس احذية نسائية country:  sa in  0.008811337499840496 minutes remaining queries:  3\n",
      "processing done for query:  new balance shoes for men country:  ae in  0.013281627083294249 minutes remaining queries:  2\n",
      "processing done for query:  العاب country:  sa in  0.0587496500001483 minutes remaining queries:  1\n",
      "processing done for query:  iphone 13 pro max country:  sa in  0.05606711319996975 minutes remaining queries:  0\n",
      "                query country        date  \\\n",
      "0              ملصقات      sa  2025-01-02   \n",
      "1              ملصقات      sa  2025-01-03   \n",
      "2              ملصقات      sa  2025-01-04   \n",
      "3              ملصقات      sa  2025-01-05   \n",
      "4              ملصقات      sa  2025-01-06   \n",
      "..                ...     ...         ...   \n",
      "26  iphone 13 pro max      sa  2025-01-28   \n",
      "27  iphone 13 pro max      sa  2025-01-29   \n",
      "28  iphone 13 pro max      sa  2025-01-30   \n",
      "29  iphone 13 pro max      sa  2025-01-31   \n",
      "30  iphone 13 pro max      sa  2025-02-01   \n",
      "\n",
      "                                        engines_range  \\\n",
      "0   {'elastic': 2.4999139835565987, 'google': 2.50...   \n",
      "1   {'elastic': 2.499844744207381, 'google': 2.500...   \n",
      "2   {'elastic': 2.4998001770968963, 'google': 2.50...   \n",
      "3   {'elastic': 2.49970898695884, 'google': 2.5002...   \n",
      "4   {'elastic': 2.4996402485632165, 'google': 2.50...   \n",
      "..                                                ...   \n",
      "26  {'elastic': 2.4716793037585236, 'google': 2.52...   \n",
      "27  {'elastic': 2.470217217527135, 'google': 2.529...   \n",
      "28  {'elastic': 2.468870788156618, 'google': 2.531...   \n",
      "29  {'elastic': 2.4675607470768717, 'google': 2.53...   \n",
      "30  {'elastic': 2.466158567149713, 'google': 2.533...   \n",
      "\n",
      "                                      config  algo_regret  real_regret  \\\n",
      "0   UCB: S:2.621440000000001e-06, C:100000.0     0.059316     0.105816   \n",
      "1   UCB: S:2.621440000000001e-06, C:100000.0     0.058199     0.117489   \n",
      "2   UCB: S:2.621440000000001e-06, C:100000.0     0.058553     0.079361   \n",
      "3   UCB: S:2.621440000000001e-06, C:100000.0     0.058956     0.058924   \n",
      "4   UCB: S:2.621440000000001e-06, C:100000.0     0.058723     0.071316   \n",
      "..                                       ...          ...          ...   \n",
      "26  UCB: S:2.621440000000001e-06, C:100000.0     0.098583     1.146715   \n",
      "27  UCB: S:2.621440000000001e-06, C:100000.0     0.098056     1.154275   \n",
      "28  UCB: S:2.621440000000001e-06, C:100000.0     0.097644     1.110755   \n",
      "29  UCB: S:2.621440000000001e-06, C:100000.0     0.097155     1.116668   \n",
      "30  UCB: S:2.621440000000001e-06, C:100000.0     0.097158     1.110105   \n",
      "\n",
      "    algo_gmv  real_gmv  \n",
      "0   1.239277  0.192777  \n",
      "1   1.240393  0.181104  \n",
      "2   1.240039  0.280006  \n",
      "3   1.239636  0.289363  \n",
      "4   1.239869  0.267203  \n",
      "..       ...       ...  \n",
      "26  5.085742  3.901729  \n",
      "27  5.086228  3.860707  \n",
      "28  5.086629  4.026138  \n",
      "29  5.087143  3.984007  \n",
      "30  5.087125  3.959080  \n",
      "\n",
      "[651 rows x 9 columns]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T18:32:38.155714Z",
     "start_time": "2025-02-28T18:32:38.146337Z"
    }
   },
   "cell_type": "code",
   "source": "experiment_results_ucb.to_csv('../experiment_output/ucb_results_fl10q_historical_rng.csv', index=False)",
   "id": "fbe9595afbda8d6a",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
