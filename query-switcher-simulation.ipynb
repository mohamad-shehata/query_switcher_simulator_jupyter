{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T13:20:54.906448Z",
     "start_time": "2025-03-04T13:20:54.357276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "daily_aggregated_data = None\n",
    "daily_total_hits = None\n",
    "query_country_date = None\n",
    "real_avg_gmv = None\n",
    "daily_engine_data = None\n",
    "\n",
    "daily_aggregated_raw_data = pd.read_csv(\"../data/bad/daily_aggregated_data.csv\")\n",
    "daily_aggregated_data = (\n",
    "    daily_aggregated_raw_data\n",
    "    .groupby([\"query\", \"country\", \"search_engine\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"avg_gmv\", \"std_gmv\", \"min_cap\", \"max_cap\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")\n",
    "\n",
    "daily_total_hits_raw_data = pd.read_csv(\"../data/bad/daily_hits.csv\")\n",
    "daily_total_hits = (\n",
    "    daily_total_hits_raw_data\n",
    "    .groupby([\"query\", \"country\", \"date\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"total_day_hits\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")\n",
    "\n",
    "query_country_date_raw_data = pd.read_csv(\"../data/bad/query_country_date.csv\")\n",
    "query_country_date = (\n",
    "    query_country_date_raw_data\n",
    "    .groupby([\"query\", \"country\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"min_date\", \"max_date\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")\n",
    "\n",
    "real_avg_gmv_raw_data = pd.read_csv(\"../data/bad/real_avg_gmv.csv\")\n",
    "real_avg_gmv = (\n",
    "    real_avg_gmv_raw_data\n",
    "    .groupby([\"query\", \"country\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"total_real_avg_gmv\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")\n",
    "\n",
    "daily_engine_data_raw_data = pd.read_csv(\"../data/bad/daily_engine_data.csv\")\n",
    "daily_engine_data = (\n",
    "    daily_engine_data_raw_data\n",
    "    .groupby([\"query\", \"country\", \"search_engine\", \"date\"], group_keys=False)\n",
    "    .apply(lambda x: x[[\"total_daily_hits\", \"total_daily_gmv\"]]\n",
    "           .iloc[0].to_dict(), include_groups=False)\n",
    ")"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T18:02:10.223184Z",
     "start_time": "2025-03-03T18:02:10.215578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Lodaer Reader\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def get_gmv_data(query: str, country: str, engine: str) -> Tuple[float, float, float, float]:\n",
    "    if daily_aggregated_data is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country, engine) not in daily_aggregated_data:\n",
    "        return NOT_VALID_DATA, NOT_VALID_DATA, NOT_VALID_DATA, NOT_VALID_DATA\n",
    "\n",
    "    avg_gmv = daily_aggregated_data[query, country, engine][\"avg_gmv\"]\n",
    "    std_gmv = daily_aggregated_data[query, country, engine][\"std_gmv\"]\n",
    "    min_cap = daily_aggregated_data[query, country, engine][\"min_cap\"]\n",
    "    max_cap = daily_aggregated_data[query, country, engine][\"max_cap\"]\n",
    "\n",
    "    return avg_gmv, std_gmv, min_cap, max_cap\n",
    "\n",
    "\n",
    "def get_daily_total_hits(query: str, country: str, date: str) -> int:\n",
    "    if daily_total_hits is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country, date) not in daily_total_hits:\n",
    "        return NOT_VALID_DATA\n",
    "\n",
    "    if daily_total_hits[query, country, date][\"total_day_hits\"] is not None:\n",
    "        return daily_total_hits[query, country, date][\"total_day_hits\"]\n",
    "\n",
    "    return NOT_VALID_DATA\n",
    "\n",
    "\n",
    "def get_all_query_time_range(query: str, country: str) -> Tuple[str, str]:\n",
    "    if query_country_date is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country) not in query_country_date:\n",
    "        return NOT_VALID_DATA, NOT_VALID_DATA\n",
    "\n",
    "    return (query_country_date[query, country][\"min_date\"],\n",
    "            query_country_date[query, country][\"max_date\"])\n",
    "\n",
    "\n",
    "def get_real_avg_gmv(query: str, country: str) -> float:\n",
    "    if real_avg_gmv is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country) not in real_avg_gmv:\n",
    "        return NOT_VALID_DATA\n",
    "\n",
    "    return real_avg_gmv[query, country][\"total_real_avg_gmv\"]\n",
    "\n",
    "\n",
    "def get_daily_engine_data(query: str, country: str, engine: str, date: str) -> Tuple[float, int]:\n",
    "    if daily_engine_data is None:\n",
    "        raise Exception(\"Data not loaded\")\n",
    "\n",
    "    if (query, country, engine, date) not in daily_engine_data:\n",
    "        return NOT_VALID_DATA, NOT_VALID_DATA\n",
    "\n",
    "    total_daily_gmv = daily_engine_data[query, country, engine, date][\"total_daily_gmv\"]\n",
    "    total_daily_hits = daily_engine_data[query, country, engine, date][\"total_daily_hits\"]\n",
    "    return total_daily_gmv, total_daily_hits"
   ],
   "id": "777cd7248316d923",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T11:19:00.170743Z",
     "start_time": "2025-03-04T11:19:00.162623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "\n",
    "NOT_VALID_DATA = -1.0\n",
    "Z_SCORE = 1.96\n",
    "MIN_ENGINE_RANGE = 0.03\n",
    "DEFAULT_ENGINES_SPLIT = {\n",
    "    'elastic': 0.2,\n",
    "    'google': 0.8\n",
    "}"
   ],
   "id": "3d5bd903ec3254e7",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T09:58:21.778465Z",
     "start_time": "2025-03-04T09:58:21.774899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Utils\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "def adjusted_softmax(arr: np.array, min_val: float) -> np.array:\n",
    "    arr = softmax(arr)\n",
    "    # ensure that every element is at least min_val\n",
    "    arr = np.maximum(arr, min_val)\n",
    "    # re-normalize the array\n",
    "    arr = arr / np.sum(arr)\n",
    "\n",
    "    return arr\n",
    "\n",
    "def generate_gmv_sample(avg: float, std: float, min_cap: float, max_cap: float) -> float:\n",
    "    selected_gmv = np.random.normal(avg, std)\n",
    "    return min(max_cap, max(selected_gmv, min_cap))  # capping"
   ],
   "id": "f69a076250e60b25",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T10:03:44.490409Z",
     "start_time": "2025-03-04T10:03:44.483643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Algorithms\n",
    "\n",
    "from typing import List, Dict\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class ScoringAlgorithm(ABC):\n",
    "    @abstractmethod\n",
    "    def get_score(self, engines_gmvs: List[float]) -> List[float]:\n",
    "        pass\n",
    "\n",
    "\n",
    "class UCBScoringAlgorithm(ScoringAlgorithm):\n",
    "\n",
    "    def __init__(self, S: float, C: float):\n",
    "        self.S = S\n",
    "        self.C = C\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"UCB: S:{self.S}, C:{self.C}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"UCB: S:{self.S}, C:{self.C}\"\n",
    "\n",
    "    def get_score(self, engines_gmvs: List[float]) -> List[float]:\n",
    "        total_engine_hits = sum(len(engine_gmv) for engine_gmv in engines_gmvs)\n",
    "        agg_hits = [len(engine_gmv) for engine_gmv in engines_gmvs]\n",
    "        agg_gmvs = [sum(engine_gmv) for engine_gmv in engines_gmvs]\n",
    "\n",
    "        agg_gmvs = np.array(agg_gmvs)\n",
    "        agg_hits = np.array(agg_hits)\n",
    "        agg_hits = np.maximum(agg_hits, 1)\n",
    "        ucb_res = softmax((agg_gmvs + self.C * np.sqrt(np.log(total_engine_hits) / agg_hits)) * self.S)\n",
    "\n",
    "        return ucb_res.tolist()\n",
    "\n",
    "\n",
    "THOMPSON_ITERATIONS = 10000\n",
    "\n",
    "\n",
    "class ThompsonScoringAlgorithm(ScoringAlgorithm):\n",
    "\n",
    "    def __init__(self, S: float, n_iterations=THOMPSON_ITERATIONS):\n",
    "        self.S = S\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"TS: S:{self.S}, N:{self.n_iterations}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TS: S:{self.S}, N:{self.n_iterations}\"\n",
    "\n",
    "    def get_score(self, engines_gmvs: List[float]) -> List[float]:\n",
    "        avg_gmvs = [np.mean(engine_gmvs) for engine_gmvs in engines_gmvs]\n",
    "        std_gmvs = [np.std(engine_gmvs) for engine_gmvs in engines_gmvs]\n",
    "        min_caps = [max(0, avg - std * Z_SCORE) for avg, std in zip(avg_gmvs, std_gmvs)]\n",
    "        max_caps = [avg + std * Z_SCORE for avg, std in zip(avg_gmvs, std_gmvs)]\n",
    "\n",
    "        num_elements = len(engines_gmvs)\n",
    "        scores = [0] * num_elements\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            sampled_gmvs = [generate_gmv_sample(avg, std, min_cap, max_cap) for avg, std, min_cap, max_cap in\n",
    "                            zip(avg_gmvs, std_gmvs, min_caps, max_caps)]\n",
    "            max_sampled_gmv = max(sampled_gmvs)\n",
    "            scores = [score + 1 if sampled_gmv == max_sampled_gmv else score for score, sampled_gmv in\n",
    "                      zip(scores, sampled_gmvs)]\n",
    "\n",
    "        scores = np.array(scores)\n",
    "        thompson_res = adjusted_softmax((scores / self.n_iterations) * self.S, MIN_ENGINE_RANGE)\n",
    "\n",
    "        return thompson_res.tolist()\n",
    "\n"
   ],
   "id": "f7a82d8e394922ce",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T11:19:23.183626Z",
     "start_time": "2025-03-04T11:19:23.164303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# processing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class SimulationResult:\n",
    "    def __init__(self):\n",
    "        self.total_avg_regrets: List[float] = []\n",
    "        self.total_avg_real_regrets: List[float] = []\n",
    "        self.avg_gmvs: List[float] = []\n",
    "        self.total_avg_real_gmvs: List[float] = []\n",
    "        self.engines_ranges: List[Dict[str, float]] = []\n",
    "        self.days: List[str] = []\n",
    "\n",
    "\n",
    "class EngineAggData:\n",
    "    def __init__(self, avg_gmv: float, std_gmv: float, min_cap: float, max_cap: float):\n",
    "        self.avg_gmv = avg_gmv\n",
    "        self.std_gmv = std_gmv\n",
    "        self.min_cap = min_cap\n",
    "        self.max_cap = max_cap\n",
    "\n",
    "\n",
    "class EngineDailyData:\n",
    "    def __init__(self, daily_gmv: float, daily_hits: int):\n",
    "        self.daily_gmv = daily_gmv\n",
    "        self.daily_hits = daily_hits\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, total_gmv: float, total_regret: float, total_hits: int):\n",
    "        self.total_gmv = total_gmv\n",
    "        self.total_regret = total_regret\n",
    "        self.total_hits = total_hits\n",
    "\n",
    "\n",
    "def run_algorithm(query: str, country: str, start_date: str, end_date: str,\n",
    "                  scoring_algorithm: ScoringAlgorithm, engines: List[str] = None,\n",
    "                  default_ranges:Dict[str, float] = None) -> SimulationResult:\n",
    "    if engines is None:\n",
    "        engines = ['elastic', 'google']\n",
    "\n",
    "    algo_data = Data(0, 0, 0)\n",
    "    real_data = Data(0, 0, 0)\n",
    "    engines_sofar_gmv = {engine: [] for engine in engines}\n",
    "    engines_range = {engine: 1 / len(engines) for engine in engines}\n",
    "    if default_ranges is not None:\n",
    "        engines_range = default_ranges\n",
    "    simulationResult = SimulationResult()\n",
    "    # use this if engine is introduced in the middle of the simulation\n",
    "    is_engine_active = {engine: False for engine in engines}\n",
    "\n",
    "    # Get the real aggregated gmv data for each engine\n",
    "    engines_agg_data = {}\n",
    "    for engine in engines:\n",
    "        avg_gmv, std_gmv, min_cap, max_cap = get_gmv_data(query, country, engine)\n",
    "        if avg_gmv == NOT_VALID_DATA:\n",
    "            return simulationResult\n",
    "        engines_agg_data[engine] = EngineAggData(avg_gmv, std_gmv, min_cap, max_cap)\n",
    "\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "    for current_date in date_range:\n",
    "        current_date_str = current_date.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Get the real daily gmv data for each engine\n",
    "        engines_daily_data = {}\n",
    "        for engine in engines:\n",
    "            daily_gmv, daily_hits = get_daily_engine_data(query, country, engine, current_date_str)\n",
    "            if daily_hits == NOT_VALID_DATA:\n",
    "                daily_hits, daily_gmv = 0, 0\n",
    "            else:\n",
    "                is_engine_active[engine] = True\n",
    "            engines_daily_data[engine] = EngineDailyData(daily_gmv, daily_hits)\n",
    "\n",
    "        total_daily_hits = get_daily_total_hits(query, country, current_date_str)\n",
    "        # If data is not available for the current date, skip the current iteration\n",
    "        if total_daily_hits == NOT_VALID_DATA:\n",
    "            continue\n",
    "\n",
    "        # Get the daily algo hits for each engine\n",
    "        engines_daily_algo_hits = {}\n",
    "        for engine in engines:\n",
    "            engines_daily_algo_hits[engine] = round(total_daily_hits * engines_range[engine]) * is_engine_active[engine]\n",
    "            algo_data.total_hits += engines_daily_algo_hits[engine]\n",
    "\n",
    "        # Make sure that total_daily_hits has the same value as the sum of the hits of the all engines\n",
    "        total_daily_hits = sum(engines_daily_algo_hits.values())\n",
    "        algo_data.total_gmv += total_daily_hits\n",
    "\n",
    "        # Aggregate the total real hits for all engines\n",
    "        for engine in engines:\n",
    "            real_data.total_hits += engines_daily_data[engine].daily_hits\n",
    "\n",
    "        total_algo_daily_selected_gmv = 0\n",
    "\n",
    "        # Simulate engines gmvs\n",
    "        for engine in engines:\n",
    "            for _ in range(engines_daily_algo_hits[engine]):\n",
    "                gmv_sample = generate_gmv_sample(engines_agg_data[engine].avg_gmv, engines_agg_data[engine].std_gmv,\n",
    "                                                 engines_agg_data[engine].min_cap, engines_agg_data[engine].max_cap)\n",
    "                total_algo_daily_selected_gmv += gmv_sample\n",
    "                engines_sofar_gmv[engine].append(gmv_sample)\n",
    "\n",
    "        algo_data.total_gmv += total_algo_daily_selected_gmv\n",
    "        simulationResult.avg_gmvs.append(algo_data.total_gmv / algo_data.total_hits)\n",
    "\n",
    "        # Best daily gmv is the max avg gmv of all engines multiplied by the total daily hits\n",
    "        best_gmv = max([engines_agg_data[engine].avg_gmv for engine in engines]) * total_daily_hits\n",
    "        # Best real gmv is the max avg gmv of all engines multiplied by the total real hits\n",
    "        best_real_gmv = max([engines_agg_data[engine].avg_gmv for engine in engines]) * sum(\n",
    "            [engines_daily_data[engine].daily_hits for engine in engines])\n",
    "\n",
    "        # Calc algo regret\n",
    "        algo_data.total_regret += max(0, best_gmv - total_algo_daily_selected_gmv)\n",
    "        simulationResult.total_avg_regrets.append(algo_data.total_regret / algo_data.total_hits)\n",
    "\n",
    "        # Calc real regret\n",
    "        real_data.total_regret += max(0,\n",
    "                                      best_real_gmv - sum([engines_daily_data[engine].daily_gmv for engine in engines]))\n",
    "        simulationResult.total_avg_real_regrets.append(real_data.total_regret / real_data.total_hits)\n",
    "\n",
    "        # Calc real gmv\n",
    "        real_data.total_gmv += (sum([engines_daily_data[engine].daily_gmv for engine in engines]))\n",
    "        simulationResult.total_avg_real_gmvs.append(real_data.total_gmv / real_data.total_hits)\n",
    "\n",
    "        # Calc ranges\n",
    "        algo_scores = scoring_algorithm.get_score([engines_sofar_gmv[engine] for engine in engines])\n",
    "        engines_range = {engine: rng for engine, rng in zip(engines, algo_scores)}\n",
    "        simulationResult.engines_ranges.append(engines_range)\n",
    "\n",
    "        # Log days\n",
    "        simulationResult.days.append(current_date_str)\n",
    "\n",
    "    return simulationResult"
   ],
   "id": "59686ccf9892cd86",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:39:18.161944Z",
     "start_time": "2025-02-27T18:39:18.150177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#     total_avg_gmv_res += algorithm_avg_gmv_res\n",
    "#     total_regret_res += algorithm_avg_regret_res\n",
    "#     total_real_avg_gmv_res += curr_real_avg_gmv_res\n",
    "#     total_real_regret_res += real_avg_regret_res\n",
    "#\n",
    "# total_avg_gmv_res /= N\n",
    "# total_regret_res /= N\n",
    "# total_real_avg_gmv_res /= N\n",
    "# total_real_regret_res /= N\n",
    "\n",
    "# print(total_avg_gmv_res, total_regret_res, total_real_avg_gmv_res, total_real_regret_res, curr_range_res)\n",
    "#  -----------------------------------------------------------\n",
    "# | ThompsonScoringAlgorithm                                  |\n",
    "# | SOFTMAX_SENSITIVITY min = 0.128 max = 65.536              |\n",
    "# |                                                           |\n",
    "# | UCBScoringAlgorithm                                       |\n",
    "# | UCB_CONFIDENCE = 10000                                    |\n",
    "# | SOFTMAX_SENSITIVITY min = 2.62144e-06 max = 0.00067108864 |\n",
    "#  -----------------------------------------------------------\n"
   ],
   "id": "6f717b674ba56e26",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T14:35:53.466863Z",
     "start_time": "2025-02-22T14:35:53.092453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drow\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def show_graph(values_to_draw: List[float], days: List[str], graph_title: str, graph_label: str,\n",
    "               graph_color: str = 'b'):\n",
    "    graph_days = pd.to_datetime(days)\n",
    "    plt.plot(graph_days, values_to_draw, color=graph_color, label=graph_label)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel(graph_label)\n",
    "    plt.title(graph_title)\n",
    "    plt.gca().xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_graph_multiple(values_to_draw: List[List[float]], days: List[str], ylabel: str, graph_title: str,\n",
    "                        graph_labels: List[str], y_limit:List[float] = None):\n",
    "    graph_days = pd.to_datetime(days)\n",
    "    for i in range(len(values_to_draw)):\n",
    "        plt.plot(graph_days, values_to_draw[i], label=graph_labels[i])\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel(ylabel)\n",
    "    if y_limit is not None:\n",
    "        plt.ylim(y_limit[0], y_limit[1])\n",
    "    plt.title(graph_title)\n",
    "    plt.gca().xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    plt.legend(fontsize=8, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.style.use('dark_background')\n",
    "    plt.figure(figsize=(16, 10))\n",
    "\n",
    "    plt.show()"
   ],
   "id": "f669aba0f3d8ca4b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T13:47:09.130276Z",
     "start_time": "2025-03-04T13:20:59.936794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "# Start Experiment Thompson\n",
    "\n",
    "# Custom queries to train with\n",
    "queries_train = [\n",
    "    ('ملصقات', 'sa', '2024-12-01', '2025-02-01')\n",
    "    , ('مزيل عرق', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('adidas shoes', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('جزمة رجالي', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('puma shoes for men', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('boots', 'eg', '2024-12-01', '2025-02-01'),\n",
    "    ('samsung', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('شنط جس', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('boots for ladies', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('abaya', 'ae', '2024-12-01', '2025-02-01'),\n",
    "    ('iphone 11', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('ماكينة حلاقة', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('airpods', 'ae', '2024-12-01', '2025-02-01'),\n",
    "    ('استشوار شعر', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('سماعه بلوتوث', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('ابجوره طويله', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('لوحه جداريه', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('نيو بالانس احذية نسائية', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('new balance shoes for men', 'ae', '2024-12-01', '2025-02-01'),\n",
    "    ('العاب', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('iphone 13 pro max', 'sa', '2024-12-01', '2025-02-01')\n",
    "]\n",
    "\n",
    "column_order = ['query', 'country', 'min_date', 'max_date']\n",
    "query_country_date_raw_data = query_country_date_raw_data[column_order]\n",
    "start = 10\n",
    "end = 100\n",
    "num_of_steps = 5\n",
    "sensitivities = np.logspace(np.log10(start), np.log10(end), num=num_of_steps)\n",
    "ALGO_N_ITERATIONS = 10\n",
    "\n",
    "experiment_results = pd.DataFrame(\n",
    "    columns=['query', 'country', 'date', 'engines_range', 'config', 'algo_regret', 'real_regret', 'algo_gmv',\n",
    "             'real_gmv'])\n",
    "total_queries = len(queries_train)  #len(query_country_date_raw_data)\n",
    "\n",
    "for query_it, country_it, start_date_it, end_date_it in queries_train:  #query_country_date_raw_data.itertuples(index=False, name=None):\n",
    "    start_time = time.perf_counter()\n",
    "    for sensitivity in sensitivities:\n",
    "        res = run_algorithm(\n",
    "            query_it, country_it, start_date_it, end_date_it, ThompsonScoringAlgorithm(sensitivity, 10000),\n",
    "            ['elastic', 'google', 'she7ata_engine'])\n",
    "\n",
    "        if len(res.days) == 0:\n",
    "            break\n",
    "\n",
    "        for _ in range(ALGO_N_ITERATIONS - 1):\n",
    "            temp = run_algorithm(\n",
    "                query_it, country_it, start_date_it, end_date_it, ThompsonScoringAlgorithm(sensitivity, 10000),\n",
    "                ['elastic', 'google', 'she7ata_engine'])\n",
    "            res.total_avg_regrets = [x + y for x, y in zip(res.total_avg_regrets, temp.total_avg_regrets)]\n",
    "            res.total_avg_real_regrets = [x + y for x, y in\n",
    "                                          zip(res.total_avg_real_regrets, temp.total_avg_real_regrets)]\n",
    "            res.avg_gmvs = [x + y for x, y in zip(res.avg_gmvs, temp.avg_gmvs)]\n",
    "            res.total_avg_real_gmvs = [x + y for x, y in zip(res.total_avg_real_gmvs, temp.total_avg_real_gmvs)]\n",
    "            for i in range(len(res.engines_ranges)):\n",
    "                for k in res.engines_ranges[i].keys():\n",
    "                    res.engines_ranges[i][k] += temp.engines_ranges[i][k]\n",
    "\n",
    "        res.total_avg_regrets = [x / ALGO_N_ITERATIONS for x in res.total_avg_regrets]\n",
    "        res.total_avg_real_regrets = [x / ALGO_N_ITERATIONS for x in res.total_avg_real_regrets]\n",
    "        res.avg_gmvs = [x / ALGO_N_ITERATIONS for x in res.avg_gmvs]\n",
    "        res.total_avg_real_gmvs = [x / ALGO_N_ITERATIONS for x in res.total_avg_real_gmvs]\n",
    "        for i in range(len(res.engines_ranges)):\n",
    "            for k in res.engines_ranges[i].keys():\n",
    "                res.engines_ranges[i][k] /= ALGO_N_ITERATIONS\n",
    "\n",
    "        result_data = {}\n",
    "\n",
    "        result_data['query'] = [query_it] * len(res.days)\n",
    "        result_data['country'] = [country_it] * len(res.days)\n",
    "        result_data['date'] = res.days\n",
    "        result_data['engines_range'] = res.engines_ranges\n",
    "        result_data['config'] = [ThompsonScoringAlgorithm(sensitivity)] * len(res.days)\n",
    "        result_data['algo_regret'] = res.total_avg_regrets\n",
    "        result_data['real_regret'] = res.total_avg_real_regrets\n",
    "        result_data['algo_gmv'] = res.avg_gmvs\n",
    "        result_data['real_gmv'] = res.total_avg_real_gmvs\n",
    "\n",
    "        experiment_results = pd.concat([experiment_results, pd.DataFrame(result_data)])\n",
    "        # show_graph_multiple([[x.left for x in res.engines_ranges], [x.right for x in res.engines_ranges]], res.days, f'engines_ranges over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', ['elastic', 'google'], ['b', 'r'])\n",
    "        # show_graph(res.total_avg_regrets, res.days, f'avg_regret over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_regret', 'r')\n",
    "        # show_graph(res.total_avg_real_regrets, res.days, f'avg_real_regret over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_real_regret', 'g')\n",
    "        # show_graph(res.avg_gmvs, res.days, f'avg_gmv over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_gmv', 'b')\n",
    "    end_time = time.perf_counter()\n",
    "    process_time = (end_time - start_time) / 60\n",
    "    total_queries -= 1\n",
    "    print(\"processing done for query: \", query_it, \"country: \", country_it, 'in ', process_time, 'minutes',\n",
    "          \"remaining queries: \", total_queries)\n",
    "print(experiment_results)"
   ],
   "id": "b011f0a378c8dfc5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mshehata/noon_projects/search_team/Query Switcher/query_switcher_simulator_jupyter/.venv/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/mshehata/noon_projects/search_team/Query Switcher/query_switcher_simulator_jupyter/.venv/lib/python3.11/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/mshehata/noon_projects/search_team/Query Switcher/query_switcher_simulator_jupyter/.venv/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/mshehata/noon_projects/search_team/Query Switcher/query_switcher_simulator_jupyter/.venv/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/Users/mshehata/noon_projects/search_team/Query Switcher/query_switcher_simulator_jupyter/.venv/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/94/jmjmqm7n6b1415qd1jn3wqj54k6k6k/T/ipykernel_97239/2879330067.py:86: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  experiment_results = pd.concat([experiment_results, pd.DataFrame(result_data)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing done for query:  ملصقات country:  sa in  1.1822371277832038 minutes remaining queries:  20\n",
      "processing done for query:  مزيل عرق country:  sa in  1.218921738183902 minutes remaining queries:  19\n",
      "processing done for query:  adidas shoes country:  sa in  1.232954759716328 minutes remaining queries:  18\n",
      "processing done for query:  جزمة رجالي country:  sa in  1.196062334034165 minutes remaining queries:  17\n",
      "processing done for query:  puma shoes for men country:  sa in  1.3358185847163744 minutes remaining queries:  16\n",
      "processing done for query:  boots country:  eg in  1.2203031757002463 minutes remaining queries:  15\n",
      "processing done for query:  samsung country:  sa in  1.3747537930505738 minutes remaining queries:  14\n",
      "processing done for query:  شنط جس country:  sa in  1.1888402840161385 minutes remaining queries:  13\n",
      "processing done for query:  boots for ladies country:  sa in  1.2003922867996153 minutes remaining queries:  12\n",
      "processing done for query:  abaya country:  ae in  1.2009870840333556 minutes remaining queries:  11\n",
      "processing done for query:  iphone 11 country:  sa in  1.2532486173673534 minutes remaining queries:  10\n",
      "processing done for query:  ماكينة حلاقة country:  sa in  1.2015734722168419 minutes remaining queries:  9\n",
      "processing done for query:  airpods country:  ae in  1.298919747916322 minutes remaining queries:  8\n",
      "processing done for query:  استشوار شعر country:  sa in  1.2304520368168597 minutes remaining queries:  7\n",
      "processing done for query:  سماعه بلوتوث country:  sa in  1.2772711541668589 minutes remaining queries:  6\n",
      "processing done for query:  ابجوره طويله country:  sa in  1.2088162180501967 minutes remaining queries:  5\n",
      "processing done for query:  لوحه جداريه country:  sa in  1.1965323784660238 minutes remaining queries:  4\n",
      "processing done for query:  نيو بالانس احذية نسائية country:  sa in  1.1708828882003823 minutes remaining queries:  3\n",
      "processing done for query:  new balance shoes for men country:  ae in  1.1998035041663873 minutes remaining queries:  2\n",
      "processing done for query:  العاب country:  sa in  1.371840495133074 minutes remaining queries:  1\n",
      "processing done for query:  iphone 13 pro max country:  sa in  1.391815795149887 minutes remaining queries:  0\n",
      "                query country        date  \\\n",
      "0              ملصقات      sa  2024-12-01   \n",
      "1              ملصقات      sa  2024-12-02   \n",
      "2              ملصقات      sa  2024-12-03   \n",
      "3              ملصقات      sa  2024-12-04   \n",
      "4              ملصقات      sa  2024-12-05   \n",
      "..                ...     ...         ...   \n",
      "58  iphone 13 pro max      sa  2025-01-28   \n",
      "59  iphone 13 pro max      sa  2025-01-29   \n",
      "60  iphone 13 pro max      sa  2025-01-30   \n",
      "61  iphone 13 pro max      sa  2025-01-31   \n",
      "62  iphone 13 pro max      sa  2025-02-01   \n",
      "\n",
      "                                        engines_range                config  \\\n",
      "0   {'elastic': 0.029566913454702765, 'google': 0....   TS: S:10.0, N:10000   \n",
      "1   {'elastic': 0.029110490027315777, 'google': 0....   TS: S:10.0, N:10000   \n",
      "2   {'elastic': 0.029290151462653964, 'google': 0....   TS: S:10.0, N:10000   \n",
      "3   {'elastic': 0.028998771254066386, 'google': 0....   TS: S:10.0, N:10000   \n",
      "4   {'elastic': 0.029079382351627252, 'google': 0....   TS: S:10.0, N:10000   \n",
      "..                                                ...                   ...   \n",
      "58  {'elastic': 0.1576416889762237, 'google': 0.81...  TS: S:100.0, N:10000   \n",
      "59  {'elastic': 0.19822988779021428, 'google': 0.7...  TS: S:100.0, N:10000   \n",
      "60  {'elastic': 0.1457350948297534, 'google': 0.82...  TS: S:100.0, N:10000   \n",
      "61  {'elastic': 0.1509372044445813, 'google': 0.81...  TS: S:100.0, N:10000   \n",
      "62  {'elastic': 0.12639835389361767, 'google': 0.8...  TS: S:100.0, N:10000   \n",
      "\n",
      "    algo_regret  real_regret  algo_gmv  real_gmv  \n",
      "0      0.055015     0.000000  1.243577  0.404291  \n",
      "1      0.023109     0.000000  1.275615  0.420949  \n",
      "2      0.016727     0.021928  1.282455  0.363073  \n",
      "3      0.013885     0.017011  1.285185  0.379507  \n",
      "4      0.012041     0.022174  1.287474  0.357708  \n",
      "..          ...          ...       ...       ...  \n",
      "58     0.042188     1.032195  5.153987  3.885732  \n",
      "59     0.042574     1.037567  5.153377  3.867648  \n",
      "60     0.043449     1.019693  5.152300  3.943083  \n",
      "61     0.043293     1.024075  5.152350  3.924890  \n",
      "62     0.043466     1.022486  5.152004  3.913989  \n",
      "\n",
      "[6615 rows x 9 columns]\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T15:03:36.767183Z",
     "start_time": "2025-03-04T15:03:36.643274Z"
    }
   },
   "cell_type": "code",
   "source": "experiment_results.to_csv('../experiment_output/thompson_results_bad_engine_adjusted_softmax_sens_10_100.csv', index=False)",
   "id": "a4a7163cb944d837",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T16:16:22.773730Z",
     "start_time": "2025-03-03T16:15:41.139280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "# Start Experiment UCB\n",
    "\n",
    "queries_train_ucb = [\n",
    "    ('ملصقات', 'sa', '2024-12-01', '2025-02-01')\n",
    "    , ('مزيل عرق', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('adidas shoes', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('جزمة رجالي', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('puma shoes for men', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('boots', 'eg', '2024-12-01', '2025-02-01'),\n",
    "    ('samsung', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('شنط جس', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('boots for ladies', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('abaya', 'ae', '2024-12-01', '2025-02-01'),\n",
    "    ('iphone 11', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('ماكينة حلاقة', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('airpods', 'ae', '2024-12-01', '2025-02-01'),\n",
    "    ('استشوار شعر', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('سماعه بلوتوث', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('ابجوره طويله', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('لوحه جداريه', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('نيو بالانس احذية نسائية', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('new balance shoes for men', 'ae', '2024-12-01', '2025-02-01'),\n",
    "    ('العاب', 'sa', '2024-12-01', '2025-02-01'),\n",
    "    ('iphone 13 pro max', 'sa', '2024-12-01', '2025-02-01')\n",
    "]\n",
    "column_order_ucb = ['query', 'country', 'min_date', 'max_date']\n",
    "query_country_date_raw_data_ucb = query_country_date_raw_data[column_order_ucb]\n",
    "\n",
    "start_sens_ucb = 2.62144e-06\n",
    "end_sens_ucb = 0.00067108864\n",
    "start_conf_ucb = 100000\n",
    "end_conf_ucb = 100000\n",
    "num_of_steps_ucb = 1\n",
    "sensitivities_ucb = np.logspace(np.log10(start_sens_ucb), np.log10(end_sens_ucb), num=num_of_steps_ucb)\n",
    "confidences_ucb = np.logspace(np.log10(start_conf_ucb), np.log10(end_conf_ucb), num=num_of_steps_ucb)\n",
    "ALGO_N_ITERATIONS_UCB = 50\n",
    "\n",
    "experiment_results_ucb = pd.DataFrame(\n",
    "    columns=['query', 'country', 'date', 'engines_range', 'config', 'algo_regret', 'real_regret', 'algo_gmv',\n",
    "             'real_gmv'])\n",
    "total_queries_ucb = len(queries_train_ucb)  #len(query_country_date_raw_data)\n",
    "for query_it_ucb, country_it_ucb, start_date_it_ucb, end_date_it_ucb in queries_train_ucb:  #query_country_date_raw_data.itertuples(index=False, name=None):\n",
    "    start_time_ucb = time.perf_counter()\n",
    "    for sensitivity_ucb in sensitivities_ucb:\n",
    "        for confidence_ucb in confidences_ucb:\n",
    "            res_ucb = run_algorithm(\n",
    "                query_it_ucb, country_it_ucb, start_date_it_ucb, end_date_it_ucb,\n",
    "                UCBScoringAlgorithm(sensitivity_ucb, confidence_ucb), ['elastic', 'google'], DEFAULT_ENGINES_SPLIT)\n",
    "\n",
    "            if len(res_ucb.days) == 0:\n",
    "                break\n",
    "\n",
    "            for _ in range(ALGO_N_ITERATIONS_UCB - 1):\n",
    "                temp_ucb = run_algorithm(\n",
    "                    query_it_ucb, country_it_ucb, start_date_it_ucb, end_date_it_ucb,\n",
    "                    UCBScoringAlgorithm(sensitivity_ucb, confidence_ucb), ['elastic', 'google'], DEFAULT_ENGINES_SPLIT)\n",
    "                res_ucb.total_avg_regrets = [x + y for x, y in\n",
    "                                             zip(res_ucb.total_avg_regrets, temp_ucb.total_avg_regrets)]\n",
    "                res_ucb.total_avg_real_regrets = [x + y for x, y in\n",
    "                                                  zip(res_ucb.total_avg_real_regrets, temp_ucb.total_avg_real_regrets)]\n",
    "                res_ucb.avg_gmvs = [x + y for x, y in zip(res_ucb.avg_gmvs, temp_ucb.avg_gmvs)]\n",
    "                res_ucb.total_avg_real_gmvs = [x + y for x, y in\n",
    "                                               zip(res_ucb.total_avg_real_gmvs, temp_ucb.total_avg_real_gmvs)]\n",
    "                for i in range(len(res_ucb.engines_ranges)):\n",
    "                    for k in res_ucb.engines_ranges[i].keys():\n",
    "                        res_ucb.engines_ranges[i][k] += temp_ucb.engines_ranges[i][k]\n",
    "\n",
    "            res_ucb.total_avg_regrets = [x / ALGO_N_ITERATIONS_UCB for x in res_ucb.total_avg_regrets]\n",
    "            res_ucb.total_avg_real_regrets = [x / ALGO_N_ITERATIONS_UCB for x in res_ucb.total_avg_real_regrets]\n",
    "            res_ucb.avg_gmvs = [x / ALGO_N_ITERATIONS_UCB for x in res_ucb.avg_gmvs]\n",
    "            res_ucb.total_avg_real_gmvs = [x / ALGO_N_ITERATIONS_UCB for x in res_ucb.total_avg_real_gmvs]\n",
    "            for i in range(len(res_ucb.engines_ranges)):\n",
    "                for k in res_ucb.engines_ranges[i].keys():\n",
    "                    res_ucb.engines_ranges[i][k] /= ALGO_N_ITERATIONS\n",
    "\n",
    "            result_data_ucb = {}\n",
    "\n",
    "            result_data_ucb['query'] = [query_it_ucb] * len(res_ucb.days)\n",
    "            result_data_ucb['country'] = [country_it_ucb] * len(res_ucb.days)\n",
    "            result_data_ucb['date'] = res_ucb.days\n",
    "            result_data_ucb['engines_range'] = res_ucb.engines_ranges\n",
    "            result_data_ucb['config'] = [UCBScoringAlgorithm(sensitivity_ucb, confidence_ucb)] * len(res_ucb.days)\n",
    "            result_data_ucb['algo_regret'] = res_ucb.total_avg_regrets\n",
    "            result_data_ucb['real_regret'] = res_ucb.total_avg_real_regrets\n",
    "            result_data_ucb['algo_gmv'] = res_ucb.avg_gmvs\n",
    "            result_data_ucb['real_gmv'] = res_ucb.total_avg_real_gmvs\n",
    "\n",
    "            experiment_results_ucb = pd.concat([experiment_results_ucb, pd.DataFrame(result_data_ucb)])\n",
    "            # show_graph_multiple([[x.left for x in res.engines_ranges], [x.right for x in res.engines_ranges]], res.days, f'engines_ranges over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', ['elastic', 'google'], ['b', 'r'])\n",
    "            # show_graph(res.total_avg_regrets, res.days, f'avg_regret over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_regret', 'r')\n",
    "            # show_graph(res.total_avg_real_regrets, res.days, f'avg_real_regret over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_real_regret', 'g')\n",
    "            # show_graph(res.avg_gmvs, res.days, f'avg_gmv over dates query = {query_it}, thompson soft_max_sens = {sensitivity}', 'avg_gmv', 'b')\n",
    "    end_time_ucb = time.perf_counter()\n",
    "    process_time_ucb = (end_time_ucb - start_time_ucb) / 60\n",
    "    total_queries_ucb -= 1\n",
    "    print(\"processing done for query: \", query_it_ucb, \"country: \", country_it_ucb, 'in ', process_time_ucb, 'minutes',\n",
    "          \"remaining queries: \", total_queries_ucb)\n",
    "print(experiment_results_ucb)"
   ],
   "id": "74a2387fc1e43aa3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/jmjmqm7n6b1415qd1jn3wqj54k6k6k/T/ipykernel_52157/475052957.py:90: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  experiment_results_ucb = pd.concat([experiment_results_ucb, pd.DataFrame(result_data_ucb)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing done for query:  ملصقات country:  sa in  0.017196118750143798 minutes remaining queries:  20\n",
      "processing done for query:  مزيل عرق country:  sa in  0.024963793050361952 minutes remaining queries:  19\n",
      "processing done for query:  adidas shoes country:  sa in  0.02502900833351305 minutes remaining queries:  18\n",
      "processing done for query:  جزمة رجالي country:  sa in  0.014263135416452617 minutes remaining queries:  17\n",
      "processing done for query:  puma shoes for men country:  sa in  0.04483889305023089 minutes remaining queries:  16\n",
      "processing done for query:  boots country:  eg in  0.01595128958336621 minutes remaining queries:  15\n",
      "processing done for query:  samsung country:  sa in  0.06017094513323779 minutes remaining queries:  14\n",
      "processing done for query:  شنط جس country:  sa in  0.013725725700108644 minutes remaining queries:  13\n",
      "processing done for query:  boots for ladies country:  sa in  0.013014288200065494 minutes remaining queries:  12\n",
      "processing done for query:  abaya country:  ae in  0.015590384033566806 minutes remaining queries:  11\n",
      "processing done for query:  iphone 11 country:  sa in  0.03335999931684152 minutes remaining queries:  10\n",
      "processing done for query:  ماكينة حلاقة country:  sa in  0.014533129866564801 minutes remaining queries:  9\n",
      "processing done for query:  airpods country:  ae in  0.051759200683348654 minutes remaining queries:  8\n",
      "processing done for query:  استشوار شعر country:  sa in  0.03697174583309485 minutes remaining queries:  7\n",
      "processing done for query:  سماعه بلوتوث country:  sa in  0.05106918958335882 minutes remaining queries:  6\n",
      "processing done for query:  ابجوره طويله country:  sa in  0.026432863199928155 minutes remaining queries:  5\n",
      "processing done for query:  لوحه جداريه country:  sa in  0.02355255348326561 minutes remaining queries:  4\n",
      "processing done for query:  نيو بالانس احذية نسائية country:  sa in  0.013302190283138771 minutes remaining queries:  3\n",
      "processing done for query:  new balance shoes for men country:  ae in  0.0219513243001226 minutes remaining queries:  2\n",
      "processing done for query:  العاب country:  sa in  0.0878459020833058 minutes remaining queries:  1\n",
      "processing done for query:  iphone 13 pro max country:  sa in  0.08814548403364218 minutes remaining queries:  0\n",
      "                query country        date  \\\n",
      "0              ملصقات      sa  2024-12-01   \n",
      "1              ملصقات      sa  2024-12-02   \n",
      "2              ملصقات      sa  2024-12-03   \n",
      "3              ملصقات      sa  2024-12-04   \n",
      "4              ملصقات      sa  2024-12-05   \n",
      "..                ...     ...         ...   \n",
      "58  iphone 13 pro max      sa  2025-01-28   \n",
      "59  iphone 13 pro max      sa  2025-01-29   \n",
      "60  iphone 13 pro max      sa  2025-01-30   \n",
      "61  iphone 13 pro max      sa  2025-01-31   \n",
      "62  iphone 13 pro max      sa  2025-02-01   \n",
      "\n",
      "                                        engines_range  \\\n",
      "0   {'elastic': 2.4999116002401918, 'google': 2.50...   \n",
      "1   {'elastic': 2.49980031488201, 'google': 2.5001...   \n",
      "2   {'elastic': 2.499741335106534, 'google': 2.500...   \n",
      "3   {'elastic': 2.499655516900899, 'google': 2.500...   \n",
      "4   {'elastic': 2.4995878272327987, 'google': 2.50...   \n",
      "..                                                ...   \n",
      "58  {'elastic': 2.4156544707509555, 'google': 2.58...   \n",
      "59  {'elastic': 2.4135633174641677, 'google': 2.58...   \n",
      "60  {'elastic': 2.411263582818438, 'google': 2.588...   \n",
      "61  {'elastic': 2.4089285418385087, 'google': 2.59...   \n",
      "62  {'elastic': 2.4066772132555267, 'google': 2.59...   \n",
      "\n",
      "                                      config  algo_regret  real_regret  \\\n",
      "0   UCB: S:2.621440000000001e-06, C:100000.0     0.059500     0.000000   \n",
      "1   UCB: S:2.621440000000001e-06, C:100000.0     0.058918     0.000000   \n",
      "2   UCB: S:2.621440000000001e-06, C:100000.0     0.058641     0.021928   \n",
      "3   UCB: S:2.621440000000001e-06, C:100000.0     0.058404     0.017011   \n",
      "4   UCB: S:2.621440000000001e-06, C:100000.0     0.058188     0.022174   \n",
      "..                                       ...          ...          ...   \n",
      "58  UCB: S:2.621440000000001e-06, C:100000.0     0.096646     1.032204   \n",
      "59  UCB: S:2.621440000000001e-06, C:100000.0     0.096713     1.037567   \n",
      "60  UCB: S:2.621440000000001e-06, C:100000.0     0.096685     1.019696   \n",
      "61  UCB: S:2.621440000000001e-06, C:100000.0     0.096751     1.024067   \n",
      "62  UCB: S:2.621440000000001e-06, C:100000.0     0.096584     1.022459   \n",
      "\n",
      "    algo_gmv  real_gmv  \n",
      "0   1.239092  0.404291  \n",
      "1   1.239674  0.420949  \n",
      "2   1.239951  0.363073  \n",
      "3   1.240188  0.379507  \n",
      "4   1.240404  0.357708  \n",
      "..       ...       ...  \n",
      "58  5.087568  3.885952  \n",
      "59  5.087488  3.867876  \n",
      "60  5.087525  3.943324  \n",
      "61  5.087449  3.925140  \n",
      "62  5.087634  3.914256  \n",
      "\n",
      "[1323 rows x 9 columns]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T15:47:16.534966Z",
     "start_time": "2025-03-03T15:47:16.493059Z"
    }
   },
   "cell_type": "code",
   "source": "experiment_results_ucb.to_csv('../experiment_output/ucb_results_bad_engine.csv', index=False)",
   "id": "fbe9595afbda8d6a",
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
